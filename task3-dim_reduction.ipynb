{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1, Task 3: Dimensionality Reduction\n",
    "\n",
    "This task is devoted to dimensionality reduction. How to map high-dimensional data into low-dimensional space is an interesting topic in the machine learning field. It is related to another hot topic -- unsupervised learning. In this section, you are going to learn two different methods for this dimensionality reduction.\n",
    "\n",
    "* Principal Component Analysis (PCA)\n",
    "* t-Distributed Stochastic Neighbor Embedding (t-SNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.cifar_utils import load_data\n",
    "\n",
    "# Plot configurations\n",
    "%matplotlib inline\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We will use the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "X_train, y_train, X_test, y_test = load_data()\n",
    "X_train = X_train.reshape([50000,3,32,32]).transpose((0,2,3,1))\n",
    "X_test = X_test.reshape([10000,3,32,32]).transpose((0,2,3,1))\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "# Data organizations:\n",
    "# Train data: 49000 samples from original train set: 1~49000\n",
    "# Validation data: 1000 samples from original train set: 49000~50000\n",
    "# Test data: 10000 samples from original test set: 1~10000\n",
    "# Development data (for gradient check): 100 from the train set: 1~49000 #TODOTA is this 100 or 1000?\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_dev = 100\n",
    "\n",
    "X_val = X_train[-num_validation:]\n",
    "y_val = y_train[-num_validation:]\n",
    "\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "X_train = X_train[:num_training]\n",
    "y_train = y_train[:num_training]\n",
    "\n",
    "# Preprocessing: subtract the mean value across every dimension for training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "X_train = X_train.astype(np.float32) - mean_image.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "X_test = X_test.astype(np.float32) - mean_image\n",
    "X_dev = X_dev.astype(np.float32) - mean_image\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('Development data shape:', X_dev.shape)\n",
    "print('Development data shape', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Principal Component Analysis (PCA)\n",
    "\n",
    "<span style=\"color:red\"><strong>TODO</strong></span>: You have to complete the code in **./utils/features/pca.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.features.pca import pca_naive\n",
    "\n",
    "X_patch = X_train[:,:,:,0]\n",
    "X_patch = np.reshape(X_patch, (X_patch.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start PCA\n",
    "K = 300\n",
    "P, T = pca_naive(X_patch, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show principle components of P using a 5x5 subplot\n",
    "# Visualize P\n",
    "r = 5\n",
    "f, axarr = plt.subplots(r, r, figsize=(8,8))\n",
    "for i in range(r):\n",
    "    for j in range(r):\n",
    "        img = np.reshape(P[r*i+j], [32,32])\n",
    "        axarr[i][j].imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small set of images for test\n",
    "num_training = 49000\n",
    "num_pca = 25\n",
    "mask = np.random.choice(num_training, num_pca, replace=False)\n",
    "X_pca = X_train[mask,:,:,0]\n",
    "\n",
    "# Visualize one channel of images \n",
    "r = 5\n",
    "f, axarr = plt.subplots(r, r, figsize=(8,8))\n",
    "for i in range(r):\n",
    "    for j in range(r):\n",
    "        img = X_pca[r*i+j]\n",
    "        axarr[i][j].imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your result\n",
    "# Reduce dimension with P\n",
    "X_features = []\n",
    "for n in range(num_pca):\n",
    "    img = X_pca[n]\n",
    "    feature = np.dot(P, np.reshape(img, (-1,)))\n",
    "    X_features.append(feature)\n",
    "\n",
    "# Reconstruct image\n",
    "X_recon = []\n",
    "for n in range(num_pca):\n",
    "    feature = X_features[n]\n",
    "    img = np.reshape(np.dot(feature, P), (32,32))\n",
    "    X_recon.append(img)\n",
    "\n",
    "# Visualize results\n",
    "r = 5\n",
    "f, axarr = plt.subplots(r, r, figsize=(8,8))\n",
    "for i in range(r):\n",
    "    for j in range(r):\n",
    "        img = X_recon[r*i+j]\n",
    "        axarr[i][j].imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA + Neural network\n",
    "\n",
    "<span style=\"color:red\"><strong>TODO</strong></span>: Use PCA to preprocess images before training a neural network: \n",
    "\n",
    "1. Do PCA preprocessing on each channel of the original image separately.\n",
    "2. Stack PCA features from three channels into one vector, and use that vector as an input for MLP.\n",
    "3. Train the MLP and show the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_funcs import train, test\n",
    "from utils.classifiers.mlp import MLP\n",
    "\n",
    "## TODO: pca preprocessing -> mlp classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><strong>TODO</strong></span>: Plot training, validation and test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:\n",
    "# plot the accuracy history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: t-SNE (optional, bonus +10 points)\n",
    "\n",
    "t-SNE is is a machine learning algorithm for nonlinear dimensionality reduction developed by Geoffrey Hinton and Laurens van der Maaten. It is also a good way of visualizing high-dimensional data in 2D. We show its application for CIFAR10. Later it will be re-used in a CNN network. Experimenting with t-SNE can be fun. One thing to try is to visualize the output of each layer of MLP to observe the differences.\n",
    "\n",
    "<p style=\"line-height: 1.2;\">[1] Maaten, Laurens van der, and Geoffrey Hinton. \"Visualizing data using t-SNE.\" Journal of Machine Learning Research 9.Nov (2008): 2579-2605.</p>\n",
    "<p style=\"line-height: 1.2;\">[2] Adaptive learning rate scheme by Jacobs https://www.willamette.edu/~gorr/classes/cs449/Momentum/deltabardelta.html</p>\n",
    "<p style=\"line-height: 1.2;\">[3] http://cs.stanford.edu/people/karpathy/cnnembed/</p>\n",
    "<p style=\"line-height: 1.2;\">[4] How to Use t-SNE Effectively, with examples.\n",
    " https://distill.pub/2016/misread-tsne</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.features.tsne import tsne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tSNE of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_select = np.random.choice(10000, 500, replace=False)\n",
    "X = X_test[random_select,:,:,0].reshape(500,1024).astype('float')/255.0\n",
    "tic = time.time()\n",
    "Y = tsne(X, low_dim=2, perplexity=30.0)\n",
    "print(\"it takes {} seconds\".format(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize tSNE of original data\n",
    "labels = y_test[random_select]\n",
    "colors = np.random.rand(10,3)\n",
    "color_labels = [colors[int(i)] for i in labels.tolist()]\n",
    "plt.scatter(Y[:,0], Y[:,1], 20, color_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tSNE of data after two hidden layers\n",
    "\n",
    "Do visualization of the tSNE of data after going through MLP. In the visualization result, you should find that in comparison with the tSNE of original data where all data points mess up with each other. While the tSNE of data after two-layer networks would be shown as multiple clusters in a 2D panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP model\n",
    "model = MLP(input_dim=3072, hidden_dims=[100], num_classes=10, reg=0.1, weight_scale=1e-3)\n",
    "\n",
    "num_epoch = 10\n",
    "batch_size = 200\n",
    "lr = 1e-3\n",
    "verbose = False\n",
    "train_acc_hist, val_acc_hist = train(model, X_train, y_train, X_val, y_val, \n",
    "                  num_epoch=num_epoch, batch_size=batch_size, learning_rate=lr, verbose=verbose)\n",
    "test(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><strong>TODO</strong></span>: Do visualization of the tSNE of data after going through MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tSNE\n",
    "X = X_test[random_select]\n",
    "tic = time.time()\n",
    "# TODO:\n",
    "# You need to first go through two hidden layers.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# End TODO\n",
    "print(\"it takes {} seconds\".format(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# visualize tSNE 2D representation of data after two hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><strong>TODO</strong></span>: Try tuning the parameters of tSNE, do visualization of the new tSNE of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Tune the parameter, show the results.\n",
    "# run tSNE\n",
    "X = X_test[random_select]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"it takes {} seconds\".format(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# visualize tSNE 2D representation of data after two hidden layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
